{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import boto3\n",
        "from awsglue.transforms import *\n",
        "from awsglue.utils import getResolvedOptions\n",
        "from pyspark.context import SparkContext\n",
        "from awsglue.context import GlueContext\n",
        "from awsglue.job import Job\n",
        "from awsglue import DynamicFrame\n",
        "\n"
      ],
      "metadata": {
        "id": "s1xBrOZQiSw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuration ---\n",
        "# Ensure that these configuration values are managed securely in a production environment.\n",
        "glue_db = \"airline_cleaned_data_db\"  # Glue database name where source tables reside\n",
        "redshift_cluster_id = \"my-redshift-cluster\"  # Redshift cluster identifier (ensure correct IAM role permissions)\n",
        "redshift_db = \"dev\"  # Redshift database name\n",
        "redshift_user = \"awsuser\"  # Redshift username\n",
        "redshift_schema = \"public\"  # Redshift schema to store the tables (can be customized)\n",
        "region = \"ap-south-1\"  # AWS region where the services are hosted\n",
        "\n"
      ],
      "metadata": {
        "id": "X1e9b56kiUaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize boto3 clients for Glue and Redshift Data APIs\n",
        "glue = boto3.client(\"glue\", region_name=region)\n",
        "redshift = boto3.client(\"redshift-data\", region_name=region)\n",
        "\n"
      ],
      "metadata": {
        "id": "F4izIc-CiWCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Map Glue data types to Redshift data types for proper table creation\n",
        "def map_glue_to_redshift(glue_type):\n",
        "    \"\"\"\n",
        "    Maps AWS Glue data types to Redshift compatible data types for table creation.\n",
        "    \"\"\"\n",
        "    mapping = {\n",
        "        \"string\": \"VARCHAR(256)\",\n",
        "        \"int\": \"INTEGER\",\n",
        "        \"bigint\": \"BIGINT\",\n",
        "        \"double\": \"FLOAT8\",\n",
        "        \"float\": \"FLOAT4\",\n",
        "        \"boolean\": \"BOOLEAN\",\n",
        "        \"timestamp\": \"TIMESTAMP\",\n",
        "        \"date\": \"DATE\"\n",
        "    }\n",
        "    return mapping.get(glue_type.lower(), \"VARCHAR(256)\")  # Default to VARCHAR for unsupported types\n",
        "\n",
        "# Read data from Glue catalog into dynamic frames\n",
        "args = getResolvedOptions(sys.argv, ['JOB_NAME'])\n",
        "sc = SparkContext()\n",
        "glueContext = GlueContext(sc)\n",
        "spark = glueContext.spark_session\n",
        "job = Job(glueContext)\n",
        "job.init(args['JOB_NAME'], args)\n",
        "\n",
        "# Reading the tables from the Glue catalog; this assumes Glue Catalog is properly configured\n",
        "ad_arrivals_node = glueContext.create_dynamic_frame.from_catalog(database=glue_db, table_name=\"ad_arrivals\", transformation_ctx=\"ad_arrivals_node\")\n",
        "ad_flights_node = glueContext.create_dynamic_frame.from_catalog(database=glue_db, table_name=\"ad_flights\", transformation_ctx=\"ad_flights_node\")\n",
        "ad_departures_node = glueContext.create_dynamic_frame.from_catalog(database=glue_db, table_name=\"ad_departures\", transformation_ctx=\"ad_departures_node\")\n",
        "\n"
      ],
      "metadata": {
        "id": "a7pHaFSRiXnJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to write dynamic frames to Redshift, including table creation logic\n",
        "def write_to_redshift(dynamic_frame, table_name):\n",
        "    \"\"\"\n",
        "    Writes a Glue DynamicFrame to Redshift.\n",
        "    - Generates DDL based on the dynamic frame's schema.\n",
        "    - Creates the table in Redshift if it does not already exist.\n",
        "    - Loads the data into Redshift after table creation.\n",
        "    \"\"\"\n",
        "    # Extract the schema from the dynamic frame\n",
        "    columns = dynamic_frame.schema().fields\n",
        "\n",
        "    # Generate CREATE TABLE DDL\n",
        "    ddl = f\"CREATE TABLE IF NOT EXISTS {redshift_schema}.{table_name} (\\n\"\n",
        "    ddl += \",\\n\".join([\n",
        "        f\"  {col.name} {map_glue_to_redshift(col.dataType.simpleString())}\"  # Map Glue types to Redshift\n",
        "        for col in columns\n",
        "    ])\n",
        "    ddl += \"\\n);\"\n",
        "\n",
        "    # Execute the CREATE TABLE statement in Redshift\n",
        "    try:\n",
        "        result = redshift.execute_statement(\n",
        "            ClusterIdentifier=redshift_cluster_id,\n",
        "            Database=redshift_db,\n",
        "            DbUser=redshift_user,\n",
        "            Sql=ddl\n",
        "        )\n",
        "        print(f\"Table {table_name} created successfully in Redshift.\")\n",
        "    except Exception as e:\n",
        "        # Log error to CloudWatch for production troubleshooting\n",
        "        print(f\"Failed to create table '{table_name}': {e}\")\n",
        "        # In production, consider sending errors to a monitoring system (e.g., CloudWatch, SNS, etc.)\n",
        "        raise  # Re-raise exception to ensure job fails and triggers alerts\n",
        "\n",
        "    # Load the dynamic frame into the newly created Redshift table\n",
        "    try:\n",
        "        glueContext.write_dynamic_frame.from_options(\n",
        "            frame=dynamic_frame,\n",
        "            connection_type=\"redshift\",\n",
        "            connection_options={\n",
        "                \"redshiftTmpDir\": \"s3://aws-glue-assets-681451696920-ap-south-1/temporary/\",  # Temporary directory for intermediate data\n",
        "                \"useConnectionProperties\": \"true\",  # Use Glue connection properties\n",
        "                \"dbtable\": f\"{redshift_schema}.{table_name}\",\n",
        "                \"connectionName\": \"AirlineRedshiftConnection\"  # Ensure Redshift connection is properly configured in Glue Catalog\n",
        "            },\n",
        "            transformation_ctx=f\"write_{table_name}_to_redshift\"\n",
        "        )\n",
        "        print(f\"Data loaded into Redshift table {table_name}.\")\n",
        "    except Exception as e:\n",
        "        # Log error to CloudWatch for production troubleshooting\n",
        "        print(f\"Failed to load data into Redshift table '{table_name}': {e}\")\n",
        "        raise  # Re-raise exception to ensure job fails\n",
        "\n",
        "# Write the dynamic frames to Redshift (production-level)\n",
        "# In production, consider logging the time it takes to load the data and monitoring resource usage (e.g., CPU, memory)\n",
        "\n",
        "write_to_redshift(ad_arrivals_node, \"ad_arrivals\")\n",
        "write_to_redshift(ad_flights_node, \"ad_flights\")\n",
        "write_to_redshift(ad_departures_node, \"ad_departures\")\n",
        "\n",
        "# Mark the Glue job as complete\n",
        "job.commit()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DE6eiamxiajH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}